#+TITLE: Prompt Engineering Guide for Advanced Language Models
#+AUTHOR: Jason Walsh <j@wal.sh>, Claude Assistant
#+DATE: [2023-09-12 Tue]

* Introduction
This comprehensive guide provides updated information on prompt engineering techniques for advanced language models like GPT-O1, incorporating recommendations from various sources and practical examples. It aims to help you create more effective prompts, leading to better and more consistent results.

* Document Type Definition (DTD)

#+BEGIN_SRC dtd :tangle prompts.dtd
<!ELEMENT prompts (prompt+)>
<!ELEMENT prompt (instructions|context|input|output_format)*>
<!ELEMENT instructions (#PCDATA)>
<!ELEMENT context (#PCDATA)>
<!ELEMENT input (#PCDATA)>
<!ELEMENT output_format (#PCDATA)>
#+END_SRC

* XMLLint Validator
:PROPERTIES:
:header-args:shell: :tangle validate_prompts.sh
:END:

#+BEGIN_SRC shell
#!/bin/bash

# Validate prompts using xmllint
xmllint --noout --dtdvalid prompts.dtd prompts/*.xml

# Check the exit status
if [ $? -eq 0 ]; then
    echo "All prompts are valid according to the DTD."
else
    echo "Validation failed. Please check the error messages above."
fi
#+END_SRC

* Key Principles for Effective Prompting

** 1. Keep Prompts Simple and Direct
- The model understands instructions well, so avoid over-guiding it.
- Be clear and specific in your instructions.
- Avoid unnecessary complexity or verbosity.

** 2. Use Delimiters for Clarity
- Incorporate delimiters like triple quotation marks, XML tags, or section titles.
- This helps the model distinguish between different parts of the input.

** 3. Specify Output Format When Necessary
- Clearly indicate the desired format for the model's response.
- This can include specifying the length, structure, or style of the output.

** 4. Provide Context Sparingly
- When using retrieval augmented generation (RAG), limit additional context.
- Too much context can overcomplicate the model's response.

** 5. Avoid Explicit Chain of Thought Prompts
- Advanced models like GPT-O1 reason internally.
- Explicit step-by-step instructions are often unnecessary and can be counterproductive.

** 6. Use Examples Judiciously
- While examples can be helpful, they're often not needed for advanced models.
- If using examples, keep them minimal and relevant.

** 7. Break Complex Tasks into Subtasks
- For very complex tasks, consider breaking them down into smaller, more manageable prompts.
- This can help maintain focus and improve overall performance.

** 8. Iterate and Refine
- Continuously test and refine your prompts to improve performance.
- Pay attention to the model's outputs and adjust your prompts accordingly.

* Examples

** Clear and Specific Prompt
#+BEGIN_SRC xml :tangle prompts/clear_specific_prompt.xml
<prompt>
  <instructions>Summarize the following text in three sentences, focusing on the main ideas and key points.</instructions>
  <input>"""Your text goes here"""</input>
</prompt>
#+END_SRC

** Few-Shot Learning Prompt
#+BEGIN_SRC xml :tangle prompts/few_shot_learning_prompt.xml
<prompt>
  <instructions>Classify the sentiment of the following review as positive, negative, or neutral.</instructions>
  <context>
    Example 1:
    Input: "The food was delicious but the service was slow."
    Output: Neutral

    Example 2:
    Input: "I absolutely loved everything about this restaurant!"
    Output: Positive
  </context>
  <input>"""Your review text goes here"""</input>
</prompt>
#+END_SRC

** Structured Prompt
#+BEGIN_SRC xml :tangle prompts/structured_prompt.xml
<prompt>
  <instructions>Provide investment advice based on the following client information:</instructions>
  <context>
    Age: 35
    Income: $75,000
    Risk tolerance: moderate
  </context>
  <output_format>Provide advice in bullet points, covering stocks, bonds, and savings.</output_format>
</prompt>
#+END_SRC

** Role-Based Prompt
#+BEGIN_SRC xml :tangle prompts/role_based_prompt.xml
<prompt>
  <instructions>As an experienced pediatrician, provide a possible diagnosis and recommended course of action for a 5-year-old child with the following symptoms:</instructions>
  <input>
    - Fever (101Â°F)
    - Runny nose
    - Cough
    - Loss of appetite
  </input>
</prompt>
#+END_SRC

** Chain of Thought Prompt
#+BEGIN_SRC xml :tangle prompts/chain_of_thought_prompt.xml
<prompt>
  <instructions>Solve the following word problem:</instructions>
  <input>If a train travels 120 miles in 2 hours, how far will it travel in 5 hours assuming it maintains the same speed?</input>
  <output_format>Explain your reasoning step-by-step.</output_format>
</prompt>
#+END_SRC

** Context Provision Prompt
#+BEGIN_SRC xml :tangle prompts/context_provision_prompt.xml
<prompt>
  <context>You are writing a blog post for a tech-savvy audience familiar with basic programming concepts.</context>
  <instructions>Explain the concept of recursion in programming. Use an everyday analogy to illustrate the concept, provide a simple code example in Python, and discuss potential pitfalls and best practices.</instructions>
</prompt>
#+END_SRC

** Output Formatting Prompt
#+BEGIN_SRC xml :tangle prompts/output_formatting_prompt.xml
<prompt>
  <instructions>Analyze the sentiment of the following customer review:</instructions>
  <input>"""Your customer review text goes here"""</input>
  <output_format>
    Provide the output in JSON format with the following structure:
    {
      "sentiment": "positive|negative|neutral",
      "confidence": 0.0 to 1.0,
      "key_phrases": ["phrase1", "phrase2", "phrase3"]
    }
  </output_format>
</prompt>
#+END_SRC

** Iterative Refinement Prompt
#+BEGIN_SRC xml :tangle prompts/iterative_refinement_prompt.xml
<prompt>
  <instructions>Summarize the following news article in 3-5 sentences, focusing on:</instructions>
  <context>
    - Main event or topic
    - Key people or organizations involved
    - Significant impacts or outcomes
  </context>
  <input>"""Your news article text goes here"""</input>
  <output_format>Provide the summary in paragraph form, maintaining a neutral tone.</output_format>
</prompt>
#+END_SRC

* Conclusion
Effective prompt engineering is crucial for getting the best results from advanced language models. By following these updated guidelines and best practices, you can create more efficient and effective prompts, leading to improved outputs across various tasks. Remember to keep your prompts clear, concise, and tailored to the specific capabilities of the model you're using.

As language models continue to evolve, stay informed about the latest developments and adjust your prompt engineering techniques accordingly. Regular testing and refinement of your prompts will help you maintain optimal performance in your applications.
